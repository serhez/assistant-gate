#!/bin/bash
# =============================================================================
# STaR-GATE Evaluation Configuration
# =============================================================================
# Edit these variables before running the evaluation scripts.

# -----------------------------------------------------------------------------
# REQUIRED: Your Custom Model on HuggingFace
# -----------------------------------------------------------------------------
# HuggingFace model ID (e.g., "your-username/your-model-name")
# Or local path to model directory
export CUSTOM_MODEL_ID="your-username/your-model-name"

# Short name for this model (used in output directories)
export CUSTOM_MODEL_NAME="custom"

# -----------------------------------------------------------------------------
# REQUIRED: API Keys
# -----------------------------------------------------------------------------
export OPENROUTER_API_KEY="${OPENROUTER_API_KEY:-your-openrouter-api-key}"
export HF_TOKEN="${HF_TOKEN:-your-huggingface-token}"

# -----------------------------------------------------------------------------
# REQUIRED: Data Paths
# -----------------------------------------------------------------------------
# Base directory for all data outputs
export DATA_ROOT="/path/to/your/data/directory"

# Individual paths (usually derived from DATA_ROOT)
export PROMPT_PATH="${DATA_ROOT}/prompts"
export PERSONAS_PATH="${DATA_ROOT}/personas"
export GOLD_PATH="${DATA_ROOT}/gold-responses"
export SIMULATION_PATH="${DATA_ROOT}/simulated-conversations"
export LOGPROBS_PATH="${DATA_ROOT}/log-probs"
export WINRATE_PATH="${DATA_ROOT}/win-rates"
export MODEL_CACHE_DIR="${DATA_ROOT}/pretrained_models"

# Version tag for this evaluation run
export VERSION="star-2-bsft"

# -----------------------------------------------------------------------------
# REQUIRED: Project Paths
# -----------------------------------------------------------------------------
# Root directory of the assistant-gate repository
export PROJECT_ROOT="/Users/ser/dev/assistant-gate"

# Conda environment name
export CONDA_ENV="assistant-gate"

# Path to conda (adjust for your system)
export CONDA_PATH="${HOME}/miniconda3/etc/profile.d/conda.sh"

# -----------------------------------------------------------------------------
# GPU Configuration (for SLURM jobs)
# -----------------------------------------------------------------------------
# Number of GPUs per node
export NUM_GPUS=4

# Tensor parallel size (should divide NUM_GPUS evenly)
export TENSOR_PARALLEL_SIZE=4

# SLURM account/partition (customize for your cluster)
export SLURM_ACCOUNT="your-account"
export SLURM_PARTITION="gpu"
export SLURM_NODE=""  # Leave empty for any node, or specify like "-w node-name"

# -----------------------------------------------------------------------------
# Evaluation Settings
# -----------------------------------------------------------------------------
# Number of conversation turns
export MAX_TURNS=3

# Top-k conversations to keep
export TOP_K=1

# Batch size for vLLM inference (reduce if OOM)
export VLLM_BATCH_SIZE=100

# Number of return sequences for QA generation
export NUM_RETURN_SEQUENCES=10

# -----------------------------------------------------------------------------
# Oracle Model (DeepSeek via OpenRouter)
# -----------------------------------------------------------------------------
export ORACLE_MODEL="deepseek/deepseek-v3.2"
export ORACLE_TEMPERATURE=0
export ORACLE_TOP_P=0.95

# -----------------------------------------------------------------------------
# Rating Model (DeepSeek via OpenRouter)
# -----------------------------------------------------------------------------
export RATING_MODEL="deepseek/deepseek-v3.2"
export RATING_TEMPERATURE=0
export RATING_TOP_P=0.95
